import os
import requests
import re
import sys
import time
import random
import glob
import json
import threading
import subprocess
import zipfile
from tqdm import tqdm
from urllib.parse import urlparse
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- YAPILANDIRMA ---
ua_file = 'user_agents.txt'
proxy_cache_file = 'turkey_proxies_cache.json'
MAX_RETRIES = 5  # aria2 kendi retry yapƒ±yor
DOWNLOAD_DIR_DEFAULT = "Downloads"
MAX_PROXY_COUNT = 200
MIN_PROXY_THRESHOLD = 150
CACHE_VALID_HOURS = 24
ARIA2_EXE = "aria2c.exe"  # Windows i√ßin
ARIA2_ZIP = "aria2.zip"
ARIA2_URL = "https://github.com/aria2/aria2/releases/download/release-1.37.0/aria2-1.37.0-win-64bit-build1.zip"

# GLOBAL DEƒûƒ∞≈ûKENLER
PROXY_POOL = []
PROXY_STATS = {}
PROXY_AUTO_ENABLED = True
BACKGROUND_REFRESH_RUNNING = False

# G√ºncel T√ºrk Proxy Kaynaklarƒ±
TURKEY_PROXY_SOURCES = [
    'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=TR',
    'https://www.proxy-list.download/api/v1/get?type=http&country=TR',
    'https://www.proxy-list.download/api/v1/get?type=https&country=TR',
    'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt',
    'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt',
    'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt',
    'https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list-raw.txt',
]

# --- ARIA2 OTOMATƒ∞K ƒ∞NDƒ∞RME ---
def setup_aria2():
    if os.path.exists(ARIA2_EXE):
        return True
    print("üåç aria2 indiriliyor (hƒ±zlƒ± indirme i√ßin gerekli, 1-2 saniye)...")
    try:
        r = requests.get(ARIA2_URL, stream=True, timeout=30)
        r.raise_for_status()
        with open(ARIA2_ZIP, 'wb') as f:
            for chunk in r.iter_content(chunk_size=1024*1024):
                if chunk:
                    f.write(chunk)
        with zipfile.ZipFile(ARIA2_ZIP) as z:
            for member in z.namelist():
                if member.endswith('aria2c.exe'):
                    z.extract(member)
                    filename = os.path.basename(member)
                    if filename != ARIA2_EXE:
                        os.rename(filename, ARIA2_EXE)
                    break
        os.remove(ARIA2_ZIP)
        print("‚úÖ aria2c.exe ba≈üarƒ±yla indirildi!")
        return True
    except Exception as e:
        print(f"‚ùå aria2 indirilemedi: {e}")
        print("Manuel indirin: https://github.com/aria2/aria2/releases")
        return False

# --- YARDIMCI FONKSƒ∞YONLAR ---
def generate_random_ua():
    chrome_v = f"{random.randint(120, 130)}.0.{random.randint(5000, 7000)}.{random.randint(10, 200)}"
    return f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_v} Safari/537.36"

def load_ua_pool(update=False):
    pool = []
    if not update and os.path.exists(ua_file):
        try:
            with open(ua_file, 'r', encoding='utf-8') as f:
                pool = [line.strip() for line in f if line.strip()]
        except: pass
    if len(pool) < 30 or update:
        pool = [generate_random_ua() for _ in range(50)]
        with open(ua_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(pool))
    return pool

def turkish_to_english_engine(text):
    name, ext = os.path.splitext(text)
    trans = str.maketrans('ƒ±√ºƒü√∂≈ü√ßƒ∞√úƒû√ñ≈û√á -.', 'iugoscIUGOSC___')
    name = name.translate(trans)
    clean_name = re.sub(r'[^a-zA-Z0-9_]', '', name)
    clean_name = re.sub(r'_+', '_', clean_name).strip('_')
    return clean_name + (ext.lower() if ext else ".mp4")

# --- PROXY Y√ñNETƒ∞Mƒ∞ ---
def load_proxy_cache():
    global PROXY_POOL
    if os.path.exists(proxy_cache_file):
        try:
            with open(proxy_cache_file, 'r') as f:
                data = json.load(f)
                if (time.time() - data.get('timestamp', 0)) / 3600 < CACHE_VALID_HOURS:
                    PROXY_POOL = [{'proxy': p, 'response_time': 0.5} for p in data.get('proxies', [])]
                    print(f"üìÇ √ñnbellekten {len(PROXY_POOL)} proxy y√ºklendi.")
                    return True
        except: pass
    return False

def save_proxy_cache():
    global PROXY_POOL
    try:
        with open(proxy_cache_file, 'w') as f:
            json.dump({'timestamp': time.time(), 'proxies': [p['proxy'] for p in PROXY_POOL]}, f)
    except: pass

def check_proxy_location(proxy_url, timeout=8):
    proxies = {'http': proxy_url, 'https': proxy_url}
    try:
        start = time.time()
        r = requests.get('http://ip-api.com/json/', proxies=proxies, timeout=timeout)
        if r.status_code == 200:
            data = r.json()
            if data.get('countryCode') == 'TR':
                return {'working': True, 'proxy': proxy_url, 'response_time': time.time() - start}
    except: pass
    return {'working': False, 'proxy': proxy_url}

def collect_turkey_proxies(background=False):
    global PROXY_POOL, BACKGROUND_REFRESH_RUNNING
    if BACKGROUND_REFRESH_RUNNING: return
    BACKGROUND_REFRESH_RUNNING = True
    
    if not background:
        print("\nüáπüá∑ 200 adet %100 √ßalƒ±≈üan T√ºrk proxy toplanƒ±yor...")

    all_raw = set()
    for source in TURKEY_PROXY_SOURCES:
        try:
            r = requests.get(source, timeout=15)
            if r.status_code == 200:
                found = re.findall(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{2,5}', r.text)
                all_raw.update([f'http://{ip}' for ip in found])
        except: pass

    unique_raw = list(all_raw)[:1000]
    new_working = []
    with ThreadPoolExecutor(max_workers=40) as executor:
        futures = [executor.submit(check_proxy_location, p) for p in unique_raw]
        for f in tqdm(as_completed(futures), total=len(unique_raw), desc="Test", disable=background):
            res = f.result()
            if res['working']:
                new_working.append(res)
                if len(new_working) + len(PROXY_POOL) >= MAX_PROXY_COUNT:
                    break

    current = {p['proxy'] for p in PROXY_POOL}
    for p in sorted(new_working, key=lambda x: x['response_time']):
        if p['proxy'] not in current and len(PROXY_POOL) < MAX_PROXY_COUNT:
            PROXY_POOL.append(p)

    PROXY_POOL.sort(key=lambda x: x['response_time'])
    PROXY_POOL = PROXY_POOL[:MAX_PROXY_COUNT]
    save_proxy_cache()
    BACKGROUND_REFRESH_RUNNING = False
    
    if not background:
        print(f"‚úÖ {len(PROXY_POOL)} adet √ßalƒ±≈üan T√ºrk proxy hazƒ±r!")

def background_proxy_refresher():
    if len(PROXY_POOL) < MIN_PROXY_THRESHOLD and not BACKGROUND_REFRESH_RUNNING:
        threading.Thread(target=collect_turkey_proxies, args=(True,), daemon=True).start()

def get_random_working_proxy():
    global PROXY_STATS, PROXY_POOL
    if not PROXY_POOL: return None
    candidates = [p for p in PROXY_POOL if PROXY_STATS.get(p['proxy'], {}).get('f', 0) < 5]
    return random.choice(candidates[:20]) if candidates else None

def mark_proxy_result(proxy_url, success=True):
    global PROXY_POOL, PROXY_STATS
    if not proxy_url: return
    stats = PROXY_STATS.setdefault(proxy_url, {'s':0, 'f':0})
    if success:
        stats['s'] += 1
    else:
        stats['f'] += 1
        if stats['f'] >= 5:
            PROXY_POOL = [p for p in PROXY_POOL if p['proxy'] != proxy_url]
            background_proxy_refresher()

def toggle_proxy_auto():
    global PROXY_AUTO_ENABLED
    PROXY_AUTO_ENABLED = not PROXY_AUTO_ENABLED
    return PROXY_AUTO_ENABLED

def initialize_proxy_pool():
    load_ua_pool()
    if not load_proxy_cache() or len(PROXY_POOL) < 50:
        collect_turkey_proxies()

# --- ANA FONKSƒ∞YONLAR ---
def check_m3u_info(url):
    print("\nüîç XTREAM API Analizi...")
    proxy = get_random_working_proxy() if PROXY_AUTO_ENABLED else None
    proxies = {'http': proxy['proxy'], 'https': proxy['proxy']} if proxy else None
    try:
        parsed = urlparse(url)
        params = dict(re.findall(r'(\w+)=([^&]+)', parsed.query))
        username = params.get('username')
        password = params.get('password')
        if not username or not password:
            print("‚ùå Username/password bulunamadƒ±.")
            return
        api_url = f"{parsed.scheme}://{parsed.netloc}/player_api.php?username={username}&password={password}"
        r = requests.get(api_url, proxies=proxies, timeout=15).json()
        u = r.get('user_info', {})
        exp = datetime.fromtimestamp(int(u.get('exp_date', 0))) if u.get('exp_date') else "Sƒ±nƒ±rsƒ±z"
        print(f"üö¶ Durum: {u.get('status')}")
        print(f"üìÖ Biti≈ü: {exp}")
        print(f"üîó Baƒülantƒ±: {u.get('active_cons',0)} / {u.get('max_connections',0)}")
    except Exception as e:
        print("‚ùå API hatasƒ±.")

def parse_m3u_to_categories(content):
    cats = {}
    curr = "Diƒüer"
    lines = content.splitlines()
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXTINF:'):
            name_match = re.search(r',(.+)$', line)
            name = name_match.group(1).strip() if name_match else "ƒ∞simsiz"
            group_match = re.search(r'group-title="([^"]*)"', line)
            curr = group_match.group(1) if group_match else "Belirtilmemi≈ü"
            i += 1
            if i < len(lines) and lines[i].strip().startswith('http'):
                url = lines[i].strip()
                cats.setdefault(curr, []).append((url, name))
        i += 1
    return cats

def select_from_categories(categories):
    if not categories:
        print("‚ùå Kategori bulunamadƒ±.")
        return "BACK"
    names = sorted(categories.keys())
    print("\n0 - GERƒ∞")
    for i, name in enumerate(names, 1):
        print(f"{i} - {name} [{len(categories[name])}]")
    while True:
        choice = input("\nKategori se√ß: ").strip()
        if choice == '0': return "BACK"
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(names):
                selected = categories[names[idx]]
                break
        except: print("‚ùå Ge√ßersiz se√ßim.")
    print("\n0 - T√úM√úN√ú ƒ∞NDƒ∞R")
    for i, (_, name) in enumerate(selected, 1):
        print(f"{i} - {name[:70]}")
    choice = input("\nSe√ßim (0=t√ºm√º, virg√ºlle se√ß): ").strip()
    if not choice or choice == '0': return selected
    result = []
    for n in [x.strip() for x in choice.split(',') if x.strip().isdigit()]:
        try:
            result.append(selected[int(n)-1])
        except: pass
    return result or "BACK"

def folder_cleaner():
    path = input("Klas√∂r yolu (bo≈ü=Downloads): ").strip() or DOWNLOAD_DIR_DEFAULT
    if not os.path.exists(path):
        print("‚ùå Klas√∂r yok.")
        return
    fixed = 0
    for f in os.listdir(path):
        full = os.path.join(path, f)
        if os.path.isfile(full):
            new = turkish_to_english_engine(f)
            if f != new:
                try:
                    new_full = os.path.join(path, new)
                    base, ext = os.path.splitext(new)
                    i = 1
                    while os.path.exists(new_full):
                        new_full = os.path.join(path, f"{base}_{i}{ext}")
                        i += 1
                    os.rename(full, new_full)
                    print(f"üîÑ {f} ‚Üí {os.path.basename(new_full)}")
                    fixed += 1
                except: pass
    print(f"\nüìä {fixed} dosya d√ºzeltildi.")

# --- YENƒ∞ ƒ∞NDƒ∞RME MOTORU (ARIA2 ƒ∞LE HIZLI) ---
def download_engine(tasks, target_dir):
    if not tasks or tasks == "BACK": return
    if not setup_aria2():
        print("‚ùå aria2 olmadan indirme yapƒ±lamƒ±yor.")
        input("Devam i√ßin Enter...")
        return
    
    os.makedirs(target_dir, exist_ok=True)
    success_count = 0
    
    for url, name in tasks:
        clean_name = turkish_to_english_engine(name)
        out_file = clean_name
        out_path = os.path.join(target_dir, out_file)
        
        i = 1
        base, ext = os.path.splitext(clean_name)
        while os.path.exists(out_path):
            out_file = f"{base}_{i}{ext}"
            out_path = os.path.join(target_dir, out_file)
            i += 1
        
        proxy = get_random_working_proxy() if PROXY_AUTO_ENABLED else None
        proxy_str = proxy['proxy'] if proxy else None
        
        cmd = [
            ARIA2_EXE,
            '--max-connection-per-server=16',
            '--split=16',
            '--min-split-size=1M',
            '--max-tries=10',
            '--retry-wait=5',
            '--continue=true',
            '--summary-interval=5',
            '--human-readable=true',
            '--console-log-level=warn',
            '--dir=' + target_dir,
            '--out=' + out_file,
            url
        ]
        
        if proxy_str:
            cmd.append('--all-proxy=' + proxy_str)
        
        print(f"\nüé¨ ƒ∞ndiriliyor: {out_file}")
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
            for line in process.stdout:
                if any(x in line for x in ['%', 'ETA', 'DL:', 'UP:']):
                    print(line.strip())
            process.wait()
            if process.returncode == 0:
                success_count += 1
                print(f"‚úÖ TAMAMLANDI: {out_file}")
                if proxy: mark_proxy_result(proxy['proxy'], True)
            else:
                print(f"‚ùå BA≈ûARISIZ: {name}")
                if proxy: mark_proxy_result(proxy['proxy'], False)
        except Exception as e:
            print(f"‚ùå Aria2 hatasƒ±: {e}")
            if proxy: mark_proxy_result(proxy['proxy'], False)
    
    print(f"\nüéâ Oturum tamam: {success_count}/{len(tasks)} dosya indirildi (aria2 ile).")

# --- MEN√ú ---
def main_menu():
    initialize_proxy_pool()
    while True:
        os.system('cls' if os.name == 'nt' else 'clear')
        print(f"=== VOD PRO v21 (aria2 Hƒ±zlƒ± ƒ∞ndirme) ===\nüáπüá∑ Proxy: {len(PROXY_POOL)}/200 (Otomatik: {'A√ßƒ±k' if PROXY_AUTO_ENABLED else 'Kapalƒ±'})\n")
        print("1 - M3U URL Gir")
        print("2 - M3U Dosya Se√ß")
        print("3 - API Analiz")
        print("4 - UA Yenile")
        print("5 - ƒ∞sim D√ºzelt")
        print("6 - Proxy Ayar")
        print("7 - √áƒ±kƒ±≈ü")
        choice = input("\nSe√ßim: ").strip()
        
        if choice == '1':
            url = input("\nM3U URL: ").strip()
            if url:
                try:
                    content = requests.get(url, timeout=30).text
                    cats = parse_m3u_to_categories(content)
                    tasks = select_from_categories(cats)
                    download_engine(tasks, DOWNLOAD_DIR_DEFAULT)
                except Exception as e:
                    print(f"‚ùå URL hatasƒ±: {e}")
            input("\nEnter...")
            
        elif choice == '2':
            file = input("\nM3U dosya adƒ±: ").strip()
            if os.path.exists(file):
                with open(file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                cats = parse_m3u_to_categories(content)
                tasks = select_from_categories(cats)
                download_engine(tasks, DOWNLOAD_DIR_DEFAULT)
            else:
                print("‚ùå Dosya bulunamadƒ±.")
            input("\nEnter...")
            
        elif choice == '3':
            url = input("\nXtream URL: ").strip()
            if url: check_m3u_info(url)
            input("\nEnter...")
            
        elif choice == '4':
            load_ua_pool(True)
            print("‚úÖ UA havuzu yenilendi.")
            input("\nEnter...")
            
        elif choice == '5':
            folder_cleaner()
            input("\nEnter...")
            
        elif choice == '6':
            print(f"\nProxy sayƒ±sƒ±: {len(PROXY_POOL)}")
            sub = input("1 - Manuel Yenile\n2 - Otomatik A√ß/Kapa\n3 - Geri\nSe√ßim: ").strip()
            if sub == '1':
                collect_turkey_proxies()
            elif sub == '2':
                state = toggle_proxy_auto()
                print(f"‚úÖ Proxy otomatik {'A√áILDI' if state else 'KAPATILDI'}")
            input("\nEnter...")
            
        elif choice == '7':
            print("\nüëã G√∂r√º≈ü√ºr√ºz Serdar abi! Bol hƒ±z, bol indirme! üáπüá∑\n")
            break

if __name__ == "__main__":
    main_menu()
